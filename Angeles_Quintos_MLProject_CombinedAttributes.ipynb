{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project (Text-Based Gender Classification of Twitter Data using Naive Bayes and Support Vector Machine)\n",
    "# Feature Extraction using the Combination of the Randomly Chosen Meta-Attributes and the Most Significant Meta-Attributes\n",
    "## Quintos, Maria Nikki H.\n",
    "## Angeles, Angelic L.\n",
    "## BSCS-ML COM 181"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.   Importing the modules, libraries, and dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A library is essentially a collection of modules that can be called and used and we can import the libraries by using 'import' to make use of the different functions. This part of the code imports modules and libraries to have access to the functions that we will be needing to build the classification model using Naive Bayes and SVM. Python libraries such as:\n",
    "\n",
    "1. <b>Numpy</b> - works with arrays and matrices used for computation in the algorithm \n",
    "2. <b>Pandas</b> - works with data manipulation and analysis \n",
    "3. <b>Sklearn</b> - works with classification, clustering and regression\n",
    "4. <b>Re</b> - works with regular expressions which are a special sequence of characters that helps you match or find other strings or sets of strings, using a specialized syntax held in a pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Importing the dataset</b>\n",
    "\n",
    "Data is raw information, it is the representation of both human and machine observation of the world. The dataset that you should used entirely depends on what type of problem you want to solve. This study is mainly focus on the gender classification problem and in this part of the code we are importing the dataset that we will used in the classification task. The dataset collected is from Kaggle. The dataset has 26 independent variables and 20,050 data. Since we are focusing on the text-based gender classification, we will only get the “gender” and “text” variables, where in the “text” represents the Twitter user’s tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>profile_yn</th>\n",
       "      <th>profile_yn:confidence</th>\n",
       "      <th>created</th>\n",
       "      <th>...</th>\n",
       "      <th>profileimage</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>815719226</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:24</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12/5/13 1:48</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/414342229...</td>\n",
       "      <td>0</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110964</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>main; @Kan1shk3</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815719227</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:30</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/1/12 13:51</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/539604221...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>ÛÏIt felt like they were my friends and I was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7471</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>815719228</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:33</td>\n",
       "      <td>male</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/28/14 11:30</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/657330418...</td>\n",
       "      <td>1</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5617</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>clcncl</td>\n",
       "      <td>Belgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>815719229</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:10</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6/11/09 22:39</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/259703936...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1693</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>815719230</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:15</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/16/14 13:23</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/564094871...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31462</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  815719226    False   finalized                   3    10/26/15 23:24   \n",
       "1  815719227    False   finalized                   3    10/26/15 23:30   \n",
       "2  815719228    False   finalized                   3    10/26/15 23:33   \n",
       "3  815719229    False   finalized                   3    10/26/15 23:10   \n",
       "4  815719230    False   finalized                   3     10/27/15 1:15   \n",
       "\n",
       "   gender  gender:confidence profile_yn  profile_yn:confidence  \\\n",
       "0    male             1.0000        yes                    1.0   \n",
       "1    male             1.0000        yes                    1.0   \n",
       "2    male             0.6625        yes                    1.0   \n",
       "3    male             1.0000        yes                    1.0   \n",
       "4  female             1.0000        yes                    1.0   \n",
       "\n",
       "          created  ...                                       profileimage  \\\n",
       "0    12/5/13 1:48  ...  https://pbs.twimg.com/profile_images/414342229...   \n",
       "1   10/1/12 13:51  ...  https://pbs.twimg.com/profile_images/539604221...   \n",
       "2  11/28/14 11:30  ...  https://pbs.twimg.com/profile_images/657330418...   \n",
       "3   6/11/09 22:39  ...  https://pbs.twimg.com/profile_images/259703936...   \n",
       "4   4/16/14 13:23  ...  https://pbs.twimg.com/profile_images/564094871...   \n",
       "\n",
       "   retweet_count sidebar_color  \\\n",
       "0              0        FFFFFF   \n",
       "1              0        C0DEED   \n",
       "2              1        C0DEED   \n",
       "3              0        C0DEED   \n",
       "4              0             0   \n",
       "\n",
       "                                                text tweet_coord tweet_count  \\\n",
       "0  Robbie E Responds To Critics After Win Against...         NaN      110964   \n",
       "1  ÛÏIt felt like they were my friends and I was...         NaN        7471   \n",
       "2  i absolutely adore when louis starts the songs...         NaN        5617   \n",
       "3  Hi @JordanSpieth - Looking at the url - do you...         NaN        1693   \n",
       "4  Watching Neighbours on Sky+ catching up with t...         NaN       31462   \n",
       "\n",
       "    tweet_created      tweet_id   tweet_location               user_timezone  \n",
       "0  10/26/15 12:40  6.587300e+17  main; @Kan1shk3                     Chennai  \n",
       "1  10/26/15 12:40  6.587300e+17              NaN  Eastern Time (US & Canada)  \n",
       "2  10/26/15 12:40  6.587300e+17           clcncl                    Belgrade  \n",
       "3  10/26/15 12:40  6.587300e+17    Palo Alto, CA  Pacific Time (US & Canada)  \n",
       "4  10/26/15 12:40  6.587300e+17              NaN                         NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/rahulvks/gender-identification-analysis/notebook\n",
    "# https://stackabuse.com/the-naive-bayes-algorithm-in-python-with-scikit-learn/\n",
    "\n",
    "url_train = 'https://raw.githubusercontent.com/mdeff/ntds_2016/master/project/reports/twitter_gender/gender-classifier-DFE-791531.csv'\n",
    "data_with_duplicate = pd.read_csv(url_train, encoding='latin1')\n",
    "\n",
    "data_with_duplicate.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are living in the age of data and data are very significant when implementing machine learning algorithms since this is where the model gets all the information that they should process and learn. Data Pre-Processing is a technique to prepare the data to get more out of it. To have better and improved datasets that are cleaner and are more manageable to analyze and work with, we must apply this technique. The purpose of using this technique is to avoid noisy, inconsistent, and missing data that can lead to poor accuracy of the machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dropping the duplicates</b>\n",
    "\n",
    "In this part of the code we are simply removing the duplicates from the DataFrame using the 'drop_duplicates' method and storing the new DataFrame with duplicate rows removed in the 'data' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20050\n",
      "Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
      "       '_last_judgment_at', 'gender', 'gender:confidence', 'profile_yn',\n",
      "       'profile_yn:confidence', 'created', 'description', 'fav_number',\n",
      "       'gender_gold', 'link_color', 'name', 'profile_yn_gold', 'profileimage',\n",
      "       'retweet_count', 'sidebar_color', 'text', 'tweet_coord', 'tweet_count',\n",
      "       'tweet_created', 'tweet_id', 'tweet_location', 'user_timezone'],\n",
      "      dtype='object')\n",
      "18412\n"
     ]
    }
   ],
   "source": [
    "print(len(data_with_duplicate))\n",
    "print(data_with_duplicate.columns)\n",
    "#print(data_with_duplicate.shape)\n",
    "data = data_with_duplicate.sort_values('text', ascending=True).drop_duplicates('text').sort_index()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Getting the significant columns that we will used in the classification task and dealing with missing values</b>\n",
    "\n",
    "The dataset will surely have missing and noisy data because the data gathering process is not perfect, so the dataset will have many irrelevant and missing parts. Data cleaning is one of the method that we should use to solve this problem. In this part of the code, we are only getting the significant columns that we will used in the classification task which are 'text' (independent variable) that represents the Twitter user's tweets and 'gender' (dependent variable) that represents if the Twitter user is a male or female. Then after getting the significant columns, we will find all the null values in the dataset and replace it with 'XXX' just so that we can easily distinguish if there is any null or missing values in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  gender\n",
      "0  Robbie E Responds To Critics After Win Against...    male\n",
      "1  ÛÏIt felt like they were my friends and I was...    male\n",
      "2  i absolutely adore when louis starts the songs...    male\n",
      "3  Hi @JordanSpieth - Looking at the url - do you...    male\n",
      "4  Watching Neighbours on Sky+ catching up with t...  female\n",
      "cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-52e004f9ebe3>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_text_label['gender'] = data_text_label['gender'].fillna('XXX')\n"
     ]
    }
   ],
   "source": [
    "# only get the text and label.\n",
    "data_text_label = data[['text', 'gender']]\n",
    "print(data_text_label.head(5))\n",
    "\n",
    "# sanity check of our data\n",
    "if data_text_label['gender'].isnull().any():\n",
    "  data_text_label['gender'] = data_text_label['gender'].fillna('XXX')\n",
    "  print('cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data Cleaning</b>\n",
    "\n",
    "One of the data preprocessing techniques is data cleaning, by applying this technique the model can improve the accuracy and performance of the machine learning model. The Regular Expression (RegEx) method is a faster process of cleaning text data that is simpler to use compared to manually splitting the strings. Regular Expressions (RegEx) are essentially text patterns that you can use to automate searching through and replacing elements within strings of text. We convert all strings into lowercase using '.lower()' method and in this case, we used 're.sub()' method to replace irrelevant and insignificant strings or characters in the 'text' or tweets of the users such as:\n",
    "1. Converting all strings into lower case\n",
    "2. Links and urls are removed\n",
    "3. Remove all non-ASCII code\n",
    "4. Remove all punctuations\n",
    "5. Delete double spaces and replace with one space\n",
    "6. Remove special characters\n",
    "7. Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-2b824ad0f5bc>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_text_label['text'] = data_text_label.apply(lambda x: cleaning(x['text']), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robbie e responds to critics after win against...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it felt like they were my friends and i was li...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi jordanspieth looking at the url do you use ...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watching neighbours on sky catching up with th...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ive seen people on the train with lamps chairs...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bpackengineer thank you for your patience whi...</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gala bingo clubs bought for m the uk s largest...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aphmau the pic defines all mcd fangirls fanbo...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>evielady just how lovely is the tree this yea...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>how are you taking care of yourself fitfluential</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mtg deals x rank up magic the seventh one prio...</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>just put my ass on the line for you and this i...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>what the nation will be talking about after w...</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>will i even need sound effects for the diviner...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>it s a glow of satisfaction re the glow</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>giannaaa lmao dude i m hella scared for next ...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>coolyazzy ditto i m still learning the favour...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>caribbros jstsaleem i do but i don t understa...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>me too saw five lionesses drinking around the ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>craftyear isabelpascual thank you for the ret...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>all the girls went to sleep and the guys just ...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chrisaofficial i m on the right side xxx</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>yall lmfaoo right when the chorus came on a te...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>james bond premier night at the everymancinema...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sydniejr except once the hallmark movies star...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>how beautiful is the religion which teaches yo...</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>fuck you nasa is awesome</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>you leave the group chat for more than  mins a...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>as opposed to pump where it s like hi hope you...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   gender\n",
       "0   robbie e responds to critics after win against...     male\n",
       "1   it felt like they were my friends and i was li...     male\n",
       "2   i absolutely adore when louis starts the songs...     male\n",
       "3   hi jordanspieth looking at the url do you use ...     male\n",
       "4   watching neighbours on sky catching up with th...   female\n",
       "5   ive seen people on the train with lamps chairs...   female\n",
       "6    bpackengineer thank you for your patience whi...    brand\n",
       "7   gala bingo clubs bought for m the uk s largest...     male\n",
       "8    aphmau the pic defines all mcd fangirls fanbo...   female\n",
       "9    evielady just how lovely is the tree this yea...   female\n",
       "10   how are you taking care of yourself fitfluential    brand\n",
       "11  mtg deals x rank up magic the seventh one prio...    brand\n",
       "12  just put my ass on the line for you and this i...   female\n",
       "13   what the nation will be talking about after w...    brand\n",
       "14  will i even need sound effects for the diviner...   female\n",
       "15           it s a glow of satisfaction re the glow    female\n",
       "16   giannaaa lmao dude i m hella scared for next ...   female\n",
       "17   coolyazzy ditto i m still learning the favour...     male\n",
       "18   caribbros jstsaleem i do but i don t understa...     male\n",
       "19  me too saw five lionesses drinking around the ...  unknown\n",
       "20   craftyear isabelpascual thank you for the ret...   female\n",
       "21  all the girls went to sleep and the guys just ...   female\n",
       "22           chrisaofficial i m on the right side xxx   female\n",
       "23  yall lmfaoo right when the chorus came on a te...     male\n",
       "24  james bond premier night at the everymancinema...     male\n",
       "25   sydniejr except once the hallmark movies star...   female\n",
       "26  how beautiful is the religion which teaches yo...    brand\n",
       "27                          fuck you nasa is awesome     brand\n",
       "28  you leave the group chat for more than  mins a...   female\n",
       "29  as opposed to pump where it s like hi hope you...     male"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning(s):\n",
    "    s = str(s)\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"http\\S+\", \"\", s)\n",
    "    encoded_string = s.encode(\"ascii\", \"ignore\")\n",
    "    s = encoded_string.decode()\n",
    "    s = re.sub(r\"[^a-zA-Z0-9]+\", ' ', s)\n",
    "    s = re.sub(' +', ' ', s)\n",
    "    s = re.sub(r\"\\b\\d+\\b\", \"\", s)\n",
    "    s = re.sub(r'[0-9]+', '', s)\n",
    "    return s\n",
    "'''\n",
    "def sample(s):\n",
    "  return 'M'+s\n",
    "'''\n",
    "\n",
    "data_text_label['text'] = data_text_label.apply(lambda x: cleaning(x['text']), axis=1)\n",
    "data_text_label.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Extraction of Features or Creation of Randomly Chosen Meta-Attributes</b>\n",
    "\n",
    "In this part of the code, this is where we create all the methods or functions that we will used to extract the features or create the randomly chosen meta-attributes. We extracted 19 features and meta-attributes by creating our own implementation of their methods. These methods are the following:\n",
    "1. <b>count_word_in_sentence</b> - counts the number of words in a sentence.\n",
    "2. <b>count_char_in_sentence</b> - counts the number of characters in a sentence.\n",
    "3. <b>count_vowels</b> - counts the number of vowels in a text. \n",
    "4. <b>count_consonants</b> - counts the number of consonants in a text.\n",
    "5. <b>aveNum_of_char_per_word</b> - is the ratio of number of characters and number of words.\n",
    "6. <b>count_spaces</b> - counts the number of blank spaces in a text. \n",
    "7. <b>count_articles</b> - counts the number of articles in a sentence.\n",
    "8. <b>count_pronouns</b> - counts the number of pronouns in a sentence.\n",
    "9. <b>count_auxiliaryverbs</b> - counts the number of auxiliary verbs in a sentence.\n",
    "10. <b>count_conjunctions</b> - counts the number of conjunctions in a sentence.\n",
    "11. <b>count_interjections</b> - counts the number of interjections in a sentence.\n",
    "12. <b>count_prepositions</b> - counts the number of prepositions in a sentence.\n",
    "13. <b>ratioSpacesAndCharacters</b> - is the ratio of number of spaces and number of characters.\n",
    "14. <b>ratioArticlesAndWords</b> - is the ratio of number of articles and number of words.\n",
    "15. <b>ratioPronounsAndWords</b> - is the ratio of number of pronouns and number of words.\n",
    "16. <b>ratioAuxiliaryVerbsAndWords</b> - is the ratio of number of auxiliary verbs and number of words.\n",
    "17. <b>ratioConjunctionsAndWords</b> - is the ratio of number of conjunctions and number of words.\n",
    "18. <b>ratioInterjectionsAndWords</b> - is the ratio of number of interjections and number of words.\n",
    "19. <b>ratioPrepositionsAndWords</b> - is the ratio of number of prepositions and number of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_in_sentence(x):\n",
    "    word_list = x.split(' ')\n",
    "    return len(word_list)\n",
    "\n",
    "def count_char_in_sentence(char):\n",
    "    count_char = len(char) - char.count(\" \")\n",
    "    return (count_char)\n",
    "\n",
    "def count_vowels(v):\n",
    "    wordlist = list(v)\n",
    "    num_vowels=0\n",
    "    for char in wordlist:\n",
    "        if char in \"aeiou\":\n",
    "            num_vowels = num_vowels+1\n",
    "    return num_vowels\n",
    "\n",
    "def count_consonants(c):\n",
    "    wordlist = list(c)\n",
    "    num_consonants=0\n",
    "    for char in wordlist:\n",
    "        if char in \"bcdfghjklmnpqrstvwxyz\":\n",
    "            num_consonants = num_consonants+1\n",
    "    return num_consonants\n",
    "\n",
    "def aveNum_of_char_per_word(a):\n",
    "    word = a.split(' ')\n",
    "    word_split = len(word)\n",
    "    count_char = len(a) - a.count(\" \")\n",
    "    return (word_split/count_char)\n",
    "\n",
    "#def ratio(num1, num2):\n",
    "    ratio = (num1/num2)\n",
    "    return ratio\n",
    "\n",
    "#def count_lowercase(l):\n",
    "    return sum(1 for x in l if x.islower())\n",
    "\n",
    "#def count_uppercase(u):\n",
    "    return sum(1 for x in u if x.isupper())\n",
    "\n",
    "#def count_digits(d):\n",
    "    return sum(1 for x in d if x.isdigit())\n",
    "\n",
    "def count_spaces(s):\n",
    "    return sum(1 for x in s if x.isspace())\n",
    "\n",
    "#def count_quotationmarks(q):\n",
    "    wordlist = list(q)\n",
    "    num_quotationmarks = 0\n",
    "    for char in wordlist:\n",
    "        if char in '\"':\n",
    "            num_quotationmarks += 1\n",
    "    return num_quotationmarks\n",
    "\n",
    "#def count_comma(c):\n",
    "    wordlist = list(c)\n",
    "    num_comma = 0\n",
    "    for char in wordlist:\n",
    "        if char in \",\":\n",
    "            num_comma += 1\n",
    "    return num_comma\n",
    "\n",
    "#def count_colons(c):\n",
    "    wordlist = list(c)\n",
    "    num_colons = 0\n",
    "    for char in wordlist:\n",
    "        if char in \":\":\n",
    "            num_colons += 1\n",
    "    return num_colons\n",
    "\n",
    "#def count_semicolons(c):\n",
    "    wordlist = list(c)\n",
    "    num_semicolons = 0\n",
    "    for char in wordlist:\n",
    "        if char in \";\":\n",
    "            num_semicolons += 1\n",
    "    return num_semicolons\n",
    "\n",
    "#def count_questionmarks(q):\n",
    "    wordlist = list(q)\n",
    "    num_questionmarks = 0\n",
    "    for char in wordlist:\n",
    "        if char in \"?\":\n",
    "            num_questionmarks += 1\n",
    "    return num_questionmarks\n",
    "\n",
    "#def count_exclamationpoints(e):\n",
    "    wordlist = list(e)\n",
    "    num_exclamationpoints = 0\n",
    "    for char in wordlist:\n",
    "        if char in \"!\":\n",
    "            num_exclamationpoints += 1\n",
    "    return num_exclamationpoints\n",
    "\n",
    "#def count_periods(p):\n",
    "    wordlist = list(p)\n",
    "    num_periods = 0\n",
    "    for char in wordlist:\n",
    "        if char in \".\":\n",
    "            num_periods += 1\n",
    "    return num_periods\n",
    "\n",
    "#def count_sentences(s):\n",
    "    wordlist = list(s)\n",
    "    num_sentences = 0\n",
    "    for char in wordlist:\n",
    "        if char in \".\":\n",
    "            num_sentences += 1\n",
    "        elif char in \"!\":\n",
    "            num_sentences += 1\n",
    "        elif char in \"?\":\n",
    "            num_sentences += 1\n",
    "    return num_sentences\n",
    "\n",
    "def count_articles(a):\n",
    "    wordlist = a.split(' ')\n",
    "    articles = [\"the\", \"a\", \"an\", \"The\", \"A\", \"An\"]\n",
    "    num_articles = 0\n",
    "    for i in wordlist:\n",
    "        if i in articles:\n",
    "            num_articles += 1\n",
    "    return num_articles\n",
    "\n",
    "def count_pronouns(p):\n",
    "    wordlist = p.split(' ')\n",
    "    pronouns = [\"I\", \"i\", \"Me\", \"me\", \"You\", \"you\", \"He\", \"he\", \"Him\", \"him\", \"She\", \"she\", \"Her\", \"her\", \"It\", \"it\", \"We\", \"we\", \"Us\", \"us\", \"They\", \"they\", \"Them\", \"them\"]\n",
    "    num_pronouns = 0\n",
    "    for i in wordlist:\n",
    "        if i in pronouns: \n",
    "            num_pronouns += 1\n",
    "    return num_pronouns\n",
    "\n",
    "def count_auxiliaryverbs(av):\n",
    "    wordlist = av.split(' ')\n",
    "    auxiliary_verbs = [\"be\", \"am\", \"are\", \"is\", \"was\", \"were\", \"being\", \"can\", \"could\", \"do\", \"did\", \"does\", \"doing\", \"have\", \"had\", \"has\", \"having\", \"may\", \"might\", \"must\", \"shall\", \"should\", \"will\", \"would\",\"Be\", \"Am\", \"Are\", \"Is\", \"Was\", \"Were\", \"Being\", \"Can\", \"Could\", \"Do\", \"Did\", \"Does\", \"Doing\", \"Have\", \"Had\", \"Has\", \"Having\", \"May\", \"Might\", \"Must\", \"Shall\", \"Should\", \"Will\", \"Would\"]\n",
    "    num_auxiliary_verbs = 0\n",
    "    for i in wordlist:\n",
    "        if i in auxiliary_verbs:\n",
    "            num_auxiliary_verbs += 1\n",
    "    return num_auxiliary_verbs\n",
    "\n",
    "def count_conjunctions(c):\n",
    "    wordlist = c.split(' ')\n",
    "    conjunctions = [\"and\", \"but\", \"for\", \"nor\", \"or\", \"so\", \"yet\", \"And\", \"But\", \"For\", \"Nor\", \"Or\", \"So\", \"Yet\", \"after\", \"until\", \"before\", \"since\", \"because\", \"as\", \"though\", \"although\", \"where as\", \"while\", \"After\", \"Until\", \"Before\", \"Since\", \"Because\", \"As\", \"Though\", \"Although\", \"Where as\", \"While\",\"either\", \"neither\", \"not only\", \"but also\", \"both\", \"not\", \"whether\", \"just as\", \" as\", \"as much\", \"no sooner\", \"than\", \"rather\", \"Either\", \"Neither\", \"Not only\", \"But also\", \"Both\", \"Not\", \"Whether\", \"Just as\", \" As\", \"As much\", \"No sooner\", \"Than\", \"Rather\"]\n",
    "    num_conjunctions = 0\n",
    "    for i in wordlist:\n",
    "        if i in conjunctions:\n",
    "            num_conjunctions += 1\n",
    "    return num_conjunctions\n",
    "\n",
    "def count_interjections(ij):\n",
    "    wordlist = ij.split(' ')\n",
    "    interjections = [\"ah\", \"alas\", \"dear\", \"eh\", \"er\", \"god\", \"hello\", \"hey\", \"hi\", \"hmm\", \"oh\", \"o\", \"ok\", \"okay\", \"ouch\", \"uh\", \"uh-huh\", \"um\", \"umm\", \"well\", \"wow\", \"Ah\", \"Alas\", \"Dear\", \"Eh\", \"Er\", \"God\", \"Hello\", \"Hey\", \"Hi\", \"Hmm\", \"Oh\", \"O\", \"Ok\", \"Okay\", \"Ouch\", \"Uh\", \"Uh-huh\", \"Um\", \"Umm\", \"Well\", \"Wow\"]\n",
    "    num_interjections = 0\n",
    "    for i in wordlist:\n",
    "        if i in interjections:\n",
    "            num_interjections += 1\n",
    "    return num_interjections\n",
    "\n",
    "def count_prepositions(p):\n",
    "    wordlist = p.split(' ')\n",
    "    prepositions = [\"aboard\", \"about\", \"above\", \"across\", \"after\", \"against\", \"along\", \"amid\", \"among\", \"anti\", \"around\", \"as\", \"at\", \"before\", \"behind\", \"below\", \"beneath\", \"beside\", \"besides\", \"between\", \"beyond\", \"but\", \"by\", \"concerning\", \"considering\", \"despite\", \"down\", \"during\", \"except\", \"excepting\", \"excluding\", \"following\", \"for\", \"from\", \"in\", \"inside\", \"into\", \"like\", \"minus\", \"near\", \"of\", \"off\", \"on\", \"onto\", \"opposite\", \"outside\", \"over\", \"past\", \"per\", \"plus\", \"regarding\", \"round\", \"save\", \"since\", \"than\", \"through\", \"to\", \"toward\", \"towards\", \"under\", \"underneath\", \"unlike\", \"until\", \"up\", \"upon\", \"versus\", \"via\", \"with\", \"within\", \"without\"]\n",
    "    num_prepositions = 0\n",
    "    for i in wordlist:\n",
    "        if i in prepositions:\n",
    "            num_prepositions += 1\n",
    "    return num_prepositions\n",
    "\n",
    "def ratioSpacesAndCharacters(a):\n",
    "    spaces = sum(1 for x in a if x.isspace())\n",
    "    char = len(a) - a.count(\" \")\n",
    "    ratio = (spaces/char)\n",
    "    return ratio\n",
    "\n",
    "def ratioArticlesAndWords(a):\n",
    "    wordlist = a.split(' ')\n",
    "    articles = [\"the\", \"a\", \"an\", \"The\", \"A\", \"An\"]\n",
    "    num_articles = 0\n",
    "    for i in wordlist:\n",
    "        if i in articles:\n",
    "            num_articles += 1\n",
    "    \n",
    "    num_words = a.split(' ')\n",
    "    num_words = len(num_words)\n",
    "    ratio = (num_articles/num_words)\n",
    "    return ratio\n",
    "\n",
    "def ratioPronounsAndWords(a):\n",
    "    wordlist = a.split(' ')\n",
    "    pronouns = [\"I\", \"i\", \"Me\", \"me\", \"You\", \"you\", \"He\", \"he\", \"Him\", \"him\", \"She\", \"she\", \"Her\", \"her\", \"It\", \"it\", \"We\", \"we\", \"Us\", \"us\", \"They\", \"they\", \"Them\", \"them\"]\n",
    "    num_pronouns = 0\n",
    "    for i in wordlist:\n",
    "        if i in pronouns: \n",
    "            num_pronouns += 1\n",
    "    \n",
    "    num_words = a.split(' ')\n",
    "    num_words = len(num_words)\n",
    "    ratio = (num_pronouns/num_words)\n",
    "    return ratio\n",
    "\n",
    "def ratioAuxiliaryVerbsAndWords(a):\n",
    "    wordlist = a.split(' ')\n",
    "    auxiliary_verbs = [\"be\", \"am\", \"are\", \"is\", \"was\", \"were\", \"being\", \"can\", \"could\", \"do\", \"did\", \"does\", \"doing\", \"have\", \"had\", \"has\", \"having\", \"may\", \"might\", \"must\", \"shall\", \"should\", \"will\", \"would\",\"Be\", \"Am\", \"Are\", \"Is\", \"Was\", \"Were\", \"Being\", \"Can\", \"Could\", \"Do\", \"Did\", \"Does\", \"Doing\", \"Have\", \"Had\", \"Has\", \"Having\", \"May\", \"Might\", \"Must\", \"Shall\", \"Should\", \"Will\", \"Would\"]\n",
    "    num_auxiliary_verbs = 0\n",
    "    for i in wordlist:\n",
    "        if i in auxiliary_verbs:\n",
    "            num_auxiliary_verbs += 1\n",
    "    \n",
    "    num_words = a.split(' ')\n",
    "    num_words = len(num_words)\n",
    "    ratio = (num_auxiliary_verbs/num_words)\n",
    "    return ratio\n",
    "\n",
    "def ratioConjunctionsAndWords(a):\n",
    "    wordlist = a.split(' ')\n",
    "    conjunctions = [\"and\", \"but\", \"for\", \"nor\", \"or\", \"so\", \"yet\", \"And\", \"But\", \"For\", \"Nor\", \"Or\", \"So\", \"Yet\", \"after\", \"until\", \"before\", \"since\", \"because\", \"as\", \"though\", \"although\", \"where as\", \"while\", \"After\", \"Until\", \"Before\", \"Since\", \"Because\", \"As\", \"Though\", \"Although\", \"Where as\", \"While\",\"either\", \"neither\", \"not only\", \"but also\", \"both\", \"not\", \"whether\", \"just as\", \" as\", \"as much\", \"no sooner\", \"than\", \"rather\", \"Either\", \"Neither\", \"Not only\", \"But also\", \"Both\", \"Not\", \"Whether\", \"Just as\", \" As\", \"As much\", \"No sooner\", \"Than\", \"Rather\"]\n",
    "    num_conjunctions = 0\n",
    "    for i in wordlist:\n",
    "        if i in conjunctions:\n",
    "            num_conjunctions += 1\n",
    "    \n",
    "    num_words = a.split(' ')\n",
    "    num_words = len(num_words)\n",
    "    ratio = (num_conjunctions/num_words)\n",
    "    return ratio\n",
    "\n",
    "def ratioInterjectionsAndWords(a):\n",
    "    wordlist = a.split(' ')\n",
    "    interjections = [\"ah\", \"alas\", \"dear\", \"eh\", \"er\", \"god\", \"hello\", \"hey\", \"hi\", \"hmm\", \"oh\", \"o\", \"ok\", \"okay\", \"ouch\", \"uh\", \"uh-huh\", \"um\", \"umm\", \"well\", \"wow\", \"Ah\", \"Alas\", \"Dear\", \"Eh\", \"Er\", \"God\", \"Hello\", \"Hey\", \"Hi\", \"Hmm\", \"Oh\", \"O\", \"Ok\", \"Okay\", \"Ouch\", \"Uh\", \"Uh-huh\", \"Um\", \"Umm\", \"Well\", \"Wow\"]\n",
    "    num_interjections = 0\n",
    "    for i in wordlist:\n",
    "        if i in interjections:\n",
    "            num_interjections += 1\n",
    "    \n",
    "    num_words = a.split(' ')\n",
    "    num_words = len(num_words)\n",
    "    ratio = (num_interjections/num_words)\n",
    "    return ratio\n",
    "\n",
    "def ratioPrepositionsAndWords(a):\n",
    "    wordlist = a.split(' ')\n",
    "    prepositions = [\"aboard\", \"about\", \"above\", \"across\", \"after\", \"against\", \"along\", \"amid\", \"among\", \"anti\", \"around\", \"as\", \"at\", \"before\", \"behind\", \"below\", \"beneath\", \"beside\", \"besides\", \"between\", \"beyond\", \"but\", \"by\", \"concerning\", \"considering\", \"despite\", \"down\", \"during\", \"except\", \"excepting\", \"excluding\", \"following\", \"for\", \"from\", \"in\", \"inside\", \"into\", \"like\", \"minus\", \"near\", \"of\", \"off\", \"on\", \"onto\", \"opposite\", \"outside\", \"over\", \"past\", \"per\", \"plus\", \"regarding\", \"round\", \"save\", \"since\", \"than\", \"through\", \"to\", \"toward\", \"towards\", \"under\", \"underneath\", \"unlike\", \"until\", \"up\", \"upon\", \"versus\", \"via\", \"with\", \"within\", \"without\"]\n",
    "    num_prepositions = 0\n",
    "    for i in wordlist:\n",
    "        if i in prepositions:\n",
    "            num_prepositions += 1\n",
    "    \n",
    "    num_words = a.split(' ')\n",
    "    num_words = len(num_words)\n",
    "    ratio = (num_prepositions/num_words)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Application of Created Methods for Feature Extraction or Creation of Meta-Attributes in the DataFrame</b>\n",
    "\n",
    "We created a dataframe named 'duplicate' and this is where we will store our extracted features or meta-attributes. First, we insert the dataset to the dataframe and store it in the 'duplicate' variable then we apply all the 19 methods that we created from the previous step for feature extraction. Then store the value of all the result of these methods in the 'duplicate' dataframe. The dataset has now 21 columns from originally having 2 columns only which is the 'text' which represents the tweets and 'gender' columns. But now we extracted 19 (independent variables) features or meta-attributes which are LengthOfWord, LengthOfCharacter, TotalVowels, TotalConsonants, AveNumOfCharWord, TotalSpaces, TotalArticles, TotalPronouns, TotalAuxiliaryVerbs, TotalConjunctions, TotalInterjections, TotalPrepositions, RatioSpacesAndCharacters, RatioArticlesAndWords, RatioPronounsAndWords, RatioAuxiliaryVerbsAndWords, RatioConjunctionsAndWords, RatioInterjectionsAndWords, and RatioPrepositionsAndWord. Including the 'text' column which represents the user's tweets. Then, 'gender' as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>LengthOfWord</th>\n",
       "      <th>LengthOfCharacter</th>\n",
       "      <th>TotalVowels</th>\n",
       "      <th>TotalConsonants</th>\n",
       "      <th>AveNumOfCharWord</th>\n",
       "      <th>TotalSpaces</th>\n",
       "      <th>TotalArticles</th>\n",
       "      <th>TotalPronouns</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalConjunctions</th>\n",
       "      <th>TotalInterjections</th>\n",
       "      <th>TotalPrepositions</th>\n",
       "      <th>RatioSpacesAndCharacters</th>\n",
       "      <th>RatioArticlesAndWords</th>\n",
       "      <th>RatioPronounsAndWords</th>\n",
       "      <th>RatioAuxiliaryVerbsAndWords</th>\n",
       "      <th>RatioConjunctionsAndWords</th>\n",
       "      <th>RatioInterjectionsAndWords</th>\n",
       "      <th>RatioPrepositionsAndWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robbie e responds to critics after win against...</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>72</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it felt like they were my friends and i was li...</td>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi jordanspieth looking at the url do you use ...</td>\n",
       "      <td>male</td>\n",
       "      <td>21</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watching neighbours on sky catching up with th...</td>\n",
       "      <td>female</td>\n",
       "      <td>11</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ive seen people on the train with lamps chairs...</td>\n",
       "      <td>female</td>\n",
       "      <td>12</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bpackengineer thank you for your patience whi...</td>\n",
       "      <td>brand</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gala bingo clubs bought for m the uk s largest...</td>\n",
       "      <td>male</td>\n",
       "      <td>21</td>\n",
       "      <td>82</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0.256098</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aphmau the pic defines all mcd fangirls fanbo...</td>\n",
       "      <td>female</td>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>evielady just how lovely is the tree this yea...</td>\n",
       "      <td>female</td>\n",
       "      <td>19</td>\n",
       "      <td>77</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  gender  LengthOfWord  \\\n",
       "0  robbie e responds to critics after win against...    male            14   \n",
       "1  it felt like they were my friends and i was li...    male            18   \n",
       "2  i absolutely adore when louis starts the songs...    male            16   \n",
       "3  hi jordanspieth looking at the url do you use ...    male            21   \n",
       "4  watching neighbours on sky catching up with th...  female            11   \n",
       "5  ive seen people on the train with lamps chairs...  female            12   \n",
       "6   bpackengineer thank you for your patience whi...   brand            15   \n",
       "7  gala bingo clubs bought for m the uk s largest...    male            21   \n",
       "8   aphmau the pic defines all mcd fangirls fanbo...  female            13   \n",
       "9   evielady just how lovely is the tree this yea...  female            19   \n",
       "\n",
       "   LengthOfCharacter  TotalVowels  TotalConsonants  AveNumOfCharWord  \\\n",
       "0                 72           28               28          0.194444   \n",
       "1                 66           23               23          0.272727   \n",
       "2                 65           25               25          0.246154   \n",
       "3                 84           33               33          0.250000   \n",
       "4                 53           14               14          0.207547   \n",
       "5                 44           16               16          0.272727   \n",
       "6                 61           27               27          0.245902   \n",
       "7                 82           30               30          0.256098   \n",
       "8                 56           16               16          0.232143   \n",
       "9                 77           33               33          0.246753   \n",
       "\n",
       "   TotalSpaces  TotalArticles  TotalPronouns  ...  TotalConjunctions  \\\n",
       "0           13              1              0  ...                  1   \n",
       "1           17              1              4  ...                  1   \n",
       "2           15              1              4  ...                  1   \n",
       "3           20              3              1  ...                  0   \n",
       "4           10              1              0  ...                  0   \n",
       "5           11              1              0  ...                  0   \n",
       "6           14              1              2  ...                  2   \n",
       "7           20              1              0  ...                  1   \n",
       "8           12              1              0  ...                  1   \n",
       "9           18              1              1  ...                  2   \n",
       "\n",
       "   TotalInterjections  TotalPrepositions  RatioSpacesAndCharacters  \\\n",
       "0                   0                  4                  0.180556   \n",
       "1                   0                  2                  0.257576   \n",
       "2                   0                  1                  0.230769   \n",
       "3                   1                  2                  0.238095   \n",
       "4                   0                  3                  0.188679   \n",
       "5                   0                  2                  0.250000   \n",
       "6                   0                  2                  0.229508   \n",
       "7                   0                  3                  0.243902   \n",
       "8                   0                  0                  0.214286   \n",
       "9                   0                  2                  0.233766   \n",
       "\n",
       "   RatioArticlesAndWords  RatioPronounsAndWords  RatioAuxiliaryVerbsAndWords  \\\n",
       "0               0.071429               0.000000                     0.000000   \n",
       "1               0.055556               0.222222                     0.111111   \n",
       "2               0.062500               0.250000                     0.000000   \n",
       "3               0.142857               0.047619                     0.047619   \n",
       "4               0.090909               0.000000                     0.000000   \n",
       "5               0.083333               0.000000                     0.000000   \n",
       "6               0.066667               0.133333                     0.000000   \n",
       "7               0.047619               0.000000                     0.095238   \n",
       "8               0.076923               0.000000                     0.000000   \n",
       "9               0.052632               0.052632                     0.052632   \n",
       "\n",
       "   RatioConjunctionsAndWords  RatioInterjectionsAndWords  \\\n",
       "0                   0.071429                    0.000000   \n",
       "1                   0.055556                    0.000000   \n",
       "2                   0.062500                    0.000000   \n",
       "3                   0.000000                    0.047619   \n",
       "4                   0.000000                    0.000000   \n",
       "5                   0.000000                    0.000000   \n",
       "6                   0.133333                    0.000000   \n",
       "7                   0.047619                    0.000000   \n",
       "8                   0.076923                    0.000000   \n",
       "9                   0.105263                    0.000000   \n",
       "\n",
       "   RatioPrepositionsAndWords  \n",
       "0                   0.285714  \n",
       "1                   0.111111  \n",
       "2                   0.062500  \n",
       "3                   0.095238  \n",
       "4                   0.272727  \n",
       "5                   0.166667  \n",
       "6                   0.133333  \n",
       "7                   0.142857  \n",
       "8                   0.000000  \n",
       "9                   0.105263  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(count_word_in_sentence)\n",
    "duplicate['LengthOfWord'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "\n",
    "character = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(count_char_in_sentence)\n",
    "duplicate['LengthOfCharacter'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "\n",
    "numVows = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(count_vowels)\n",
    "duplicate['TotalVowels'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "numCons = pd.DataFrame(data_text_label)\n",
    "duplicate['TotalConsonants'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "AveNumOfCharPerWord = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(aveNum_of_char_per_word)\n",
    "duplicate['AveNumOfCharWord'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "numSpaces = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(count_spaces)\n",
    "duplicate['TotalSpaces'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "numArticles = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(count_articles)\n",
    "duplicate['TotalArticles'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "numPronouns = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(count_pronouns)\n",
    "duplicate['TotalPronouns'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "numAuxiliaryVerbs = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(count_auxiliaryverbs)\n",
    "duplicate['TotalAuxiliaryVerbs'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "numConjunctions = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(count_conjunctions)\n",
    "duplicate['TotalConjunctions'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "numInterjections = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(count_interjections)\n",
    "duplicate['TotalInterjections'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "numPrepositions = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(count_prepositions)\n",
    "duplicate['TotalPrepositions'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "ratioBetweenSpacesAndCharacters = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(ratioSpacesAndCharacters)\n",
    "duplicate['RatioSpacesAndCharacters'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "ratioBetweenArticlesAndWords = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(ratioArticlesAndWords)\n",
    "duplicate['RatioArticlesAndWords'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "ratioBetweenPronounsAndWords = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(ratioPronounsAndWords)\n",
    "duplicate['RatioPronounsAndWords'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "ratioBetweenAuxiliaryVerbsAndWords = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(ratioAuxiliaryVerbsAndWords)\n",
    "duplicate['RatioAuxiliaryVerbsAndWords'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "ratioBetweenConjunctionsAndWords = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(ratioConjunctionsAndWords)\n",
    "duplicate['RatioConjunctionsAndWords'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "ratioBetweenInterjectionsAndWords = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(ratioInterjectionsAndWords)\n",
    "duplicate['RatioInterjectionsAndWords'] = g\n",
    "duplicate.head(5)\n",
    "\n",
    "ratioBetweenPrepositionsAndWords = pd.DataFrame(data_text_label)\n",
    "g = data_text_label['text'].apply(ratioPrepositionsAndWords)\n",
    "duplicate['RatioPrepositionsAndWords'] = g\n",
    "duplicate.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>LengthOfWord</th>\n",
       "      <th>LengthOfCharacter</th>\n",
       "      <th>TotalVowels</th>\n",
       "      <th>TotalConsonants</th>\n",
       "      <th>AveNumOfCharWord</th>\n",
       "      <th>TotalSpaces</th>\n",
       "      <th>TotalArticles</th>\n",
       "      <th>TotalPronouns</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalConjunctions</th>\n",
       "      <th>TotalInterjections</th>\n",
       "      <th>TotalPrepositions</th>\n",
       "      <th>RatioSpacesAndCharacters</th>\n",
       "      <th>RatioArticlesAndWords</th>\n",
       "      <th>RatioPronounsAndWords</th>\n",
       "      <th>RatioAuxiliaryVerbsAndWords</th>\n",
       "      <th>RatioConjunctionsAndWords</th>\n",
       "      <th>RatioInterjectionsAndWords</th>\n",
       "      <th>RatioPrepositionsAndWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robbie e responds to critics after win against...</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>72</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it felt like they were my friends and i was li...</td>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi jordanspieth looking at the url do you use ...</td>\n",
       "      <td>male</td>\n",
       "      <td>21</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watching neighbours on sky catching up with th...</td>\n",
       "      <td>female</td>\n",
       "      <td>11</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20032</th>\n",
       "      <td>legobutts you can do quests and kill stuff wh...</td>\n",
       "      <td>male</td>\n",
       "      <td>29</td>\n",
       "      <td>106</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>view the community halloween spooktacular city...</td>\n",
       "      <td>brand</td>\n",
       "      <td>9</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20036</th>\n",
       "      <td>itsleehinchy leesqanda what s the story in ba...</td>\n",
       "      <td>female</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20042</th>\n",
       "      <td>best bloody mary brunch at the nycwff nyceff d...</td>\n",
       "      <td>brand</td>\n",
       "      <td>12</td>\n",
       "      <td>73</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20045</th>\n",
       "      <td>lookupondeath fine and i ll drink tea too i l...</td>\n",
       "      <td>female</td>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18412 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  gender  \\\n",
       "0      robbie e responds to critics after win against...    male   \n",
       "1      it felt like they were my friends and i was li...    male   \n",
       "2      i absolutely adore when louis starts the songs...    male   \n",
       "3      hi jordanspieth looking at the url do you use ...    male   \n",
       "4      watching neighbours on sky catching up with th...  female   \n",
       "...                                                  ...     ...   \n",
       "20032   legobutts you can do quests and kill stuff wh...    male   \n",
       "20034  view the community halloween spooktacular city...   brand   \n",
       "20036   itsleehinchy leesqanda what s the story in ba...  female   \n",
       "20042  best bloody mary brunch at the nycwff nyceff d...   brand   \n",
       "20045   lookupondeath fine and i ll drink tea too i l...  female   \n",
       "\n",
       "       LengthOfWord  LengthOfCharacter  TotalVowels  TotalConsonants  \\\n",
       "0                14                 72           28               28   \n",
       "1                18                 66           23               23   \n",
       "2                16                 65           25               25   \n",
       "3                21                 84           33               33   \n",
       "4                11                 53           14               14   \n",
       "...             ...                ...          ...              ...   \n",
       "20032            29                106           40               40   \n",
       "20034             9                 62           24               24   \n",
       "20036            10                 44           15               15   \n",
       "20042            12                 73           24               24   \n",
       "20045            13                 42           20               20   \n",
       "\n",
       "       AveNumOfCharWord  TotalSpaces  TotalArticles  TotalPronouns  ...  \\\n",
       "0              0.194444           13              1              0  ...   \n",
       "1              0.272727           17              1              4  ...   \n",
       "2              0.246154           15              1              4  ...   \n",
       "3              0.250000           20              3              1  ...   \n",
       "4              0.207547           10              1              0  ...   \n",
       "...                 ...          ...            ...            ...  ...   \n",
       "20032          0.273585           28              1              4  ...   \n",
       "20034          0.145161            8              1              0  ...   \n",
       "20036          0.227273            9              1              0  ...   \n",
       "20042          0.164384           11              1              0  ...   \n",
       "20045          0.309524           12              0              3  ...   \n",
       "\n",
       "       TotalConjunctions  TotalInterjections  TotalPrepositions  \\\n",
       "0                      1                   0                  4   \n",
       "1                      1                   0                  2   \n",
       "2                      1                   0                  1   \n",
       "3                      0                   1                  2   \n",
       "4                      0                   0                  3   \n",
       "...                  ...                 ...                ...   \n",
       "20032                  3                   0                  2   \n",
       "20034                  0                   0                  0   \n",
       "20036                  0                   0                  1   \n",
       "20042                  0                   0                  1   \n",
       "20045                  1                   0                  0   \n",
       "\n",
       "       RatioSpacesAndCharacters  RatioArticlesAndWords  RatioPronounsAndWords  \\\n",
       "0                      0.180556               0.071429               0.000000   \n",
       "1                      0.257576               0.055556               0.222222   \n",
       "2                      0.230769               0.062500               0.250000   \n",
       "3                      0.238095               0.142857               0.047619   \n",
       "4                      0.188679               0.090909               0.000000   \n",
       "...                         ...                    ...                    ...   \n",
       "20032                  0.264151               0.034483               0.137931   \n",
       "20034                  0.129032               0.111111               0.000000   \n",
       "20036                  0.204545               0.100000               0.000000   \n",
       "20042                  0.150685               0.083333               0.000000   \n",
       "20045                  0.285714               0.000000               0.230769   \n",
       "\n",
       "       RatioAuxiliaryVerbsAndWords  RatioConjunctionsAndWords  \\\n",
       "0                         0.000000                   0.071429   \n",
       "1                         0.111111                   0.055556   \n",
       "2                         0.000000                   0.062500   \n",
       "3                         0.047619                   0.000000   \n",
       "4                         0.000000                   0.000000   \n",
       "...                            ...                        ...   \n",
       "20032                     0.103448                   0.103448   \n",
       "20034                     0.000000                   0.000000   \n",
       "20036                     0.000000                   0.000000   \n",
       "20042                     0.000000                   0.000000   \n",
       "20045                     0.000000                   0.076923   \n",
       "\n",
       "       RatioInterjectionsAndWords  RatioPrepositionsAndWords  \n",
       "0                        0.000000                   0.285714  \n",
       "1                        0.000000                   0.111111  \n",
       "2                        0.000000                   0.062500  \n",
       "3                        0.047619                   0.095238  \n",
       "4                        0.000000                   0.272727  \n",
       "...                           ...                        ...  \n",
       "20032                    0.000000                   0.068966  \n",
       "20034                    0.000000                   0.000000  \n",
       "20036                    0.000000                   0.100000  \n",
       "20042                    0.000000                   0.083333  \n",
       "20045                    0.000000                   0.000000  \n",
       "\n",
       "[18412 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Removal of text column</b>\n",
    "\n",
    "In this part of the code, we will now remove the 'text' column since we will not use it anymore and will no longer be significant in the dataset because we already created our own features or meta-attributes that is extracted from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>LengthOfWord</th>\n",
       "      <th>LengthOfCharacter</th>\n",
       "      <th>TotalVowels</th>\n",
       "      <th>TotalConsonants</th>\n",
       "      <th>AveNumOfCharWord</th>\n",
       "      <th>TotalSpaces</th>\n",
       "      <th>TotalArticles</th>\n",
       "      <th>TotalPronouns</th>\n",
       "      <th>TotalAuxiliaryVerbs</th>\n",
       "      <th>TotalConjunctions</th>\n",
       "      <th>TotalInterjections</th>\n",
       "      <th>TotalPrepositions</th>\n",
       "      <th>RatioSpacesAndCharacters</th>\n",
       "      <th>RatioArticlesAndWords</th>\n",
       "      <th>RatioPronounsAndWords</th>\n",
       "      <th>RatioAuxiliaryVerbsAndWords</th>\n",
       "      <th>RatioConjunctionsAndWords</th>\n",
       "      <th>RatioInterjectionsAndWords</th>\n",
       "      <th>RatioPrepositionsAndWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>72</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>21</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>11</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  LengthOfWord  LengthOfCharacter  TotalVowels  TotalConsonants  \\\n",
       "0    male            14                 72           28               28   \n",
       "1    male            18                 66           23               23   \n",
       "2    male            16                 65           25               25   \n",
       "3    male            21                 84           33               33   \n",
       "4  female            11                 53           14               14   \n",
       "\n",
       "   AveNumOfCharWord  TotalSpaces  TotalArticles  TotalPronouns  \\\n",
       "0          0.194444           13              1              0   \n",
       "1          0.272727           17              1              4   \n",
       "2          0.246154           15              1              4   \n",
       "3          0.250000           20              3              1   \n",
       "4          0.207547           10              1              0   \n",
       "\n",
       "   TotalAuxiliaryVerbs  TotalConjunctions  TotalInterjections  \\\n",
       "0                    0                  1                   0   \n",
       "1                    2                  1                   0   \n",
       "2                    0                  1                   0   \n",
       "3                    1                  0                   1   \n",
       "4                    0                  0                   0   \n",
       "\n",
       "   TotalPrepositions  RatioSpacesAndCharacters  RatioArticlesAndWords  \\\n",
       "0                  4                  0.180556               0.071429   \n",
       "1                  2                  0.257576               0.055556   \n",
       "2                  1                  0.230769               0.062500   \n",
       "3                  2                  0.238095               0.142857   \n",
       "4                  3                  0.188679               0.090909   \n",
       "\n",
       "   RatioPronounsAndWords  RatioAuxiliaryVerbsAndWords  \\\n",
       "0               0.000000                     0.000000   \n",
       "1               0.222222                     0.111111   \n",
       "2               0.250000                     0.000000   \n",
       "3               0.047619                     0.047619   \n",
       "4               0.000000                     0.000000   \n",
       "\n",
       "   RatioConjunctionsAndWords  RatioInterjectionsAndWords  \\\n",
       "0                   0.071429                    0.000000   \n",
       "1                   0.055556                    0.000000   \n",
       "2                   0.062500                    0.000000   \n",
       "3                   0.000000                    0.047619   \n",
       "4                   0.000000                    0.000000   \n",
       "\n",
       "   RatioPrepositionsAndWords  \n",
       "0                   0.285714  \n",
       "1                   0.111111  \n",
       "2                   0.062500  \n",
       "3                   0.095238  \n",
       "4                   0.272727  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate = pd.DataFrame(data_text_label)\n",
    "del duplicate['text']\n",
    "duplicate.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Shifting the gender column to the rightmost part of the data</b>\n",
    "\n",
    "We now only have 20 columns since we already remove the text column and we shifted the gender column to the rightmost part of the dataframe for a cleaner look in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_shift = ['gender']\n",
    "duplicate = pd.concat([duplicate[duplicate.columns.difference(column_to_shift)], duplicate[column_to_shift]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveNumOfCharWord</th>\n",
       "      <th>LengthOfCharacter</th>\n",
       "      <th>LengthOfWord</th>\n",
       "      <th>RatioArticlesAndWords</th>\n",
       "      <th>RatioAuxiliaryVerbsAndWords</th>\n",
       "      <th>RatioConjunctionsAndWords</th>\n",
       "      <th>RatioInterjectionsAndWords</th>\n",
       "      <th>RatioPrepositionsAndWords</th>\n",
       "      <th>RatioPronounsAndWords</th>\n",
       "      <th>RatioSpacesAndCharacters</th>\n",
       "      <th>TotalArticles</th>\n",
       "      <th>TotalAuxiliaryVerbs</th>\n",
       "      <th>TotalConjunctions</th>\n",
       "      <th>TotalConsonants</th>\n",
       "      <th>TotalInterjections</th>\n",
       "      <th>TotalPrepositions</th>\n",
       "      <th>TotalPronouns</th>\n",
       "      <th>TotalSpaces</th>\n",
       "      <th>TotalVowels</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>66</td>\n",
       "      <td>18</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.246154</td>\n",
       "      <td>65</td>\n",
       "      <td>16</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>84</td>\n",
       "      <td>21</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207547</td>\n",
       "      <td>53</td>\n",
       "      <td>11</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20032</th>\n",
       "      <td>0.273585</td>\n",
       "      <td>106</td>\n",
       "      <td>29</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>0.145161</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20036</th>\n",
       "      <td>0.227273</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20042</th>\n",
       "      <td>0.164384</td>\n",
       "      <td>73</td>\n",
       "      <td>12</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20045</th>\n",
       "      <td>0.309524</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18412 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AveNumOfCharWord  LengthOfCharacter  LengthOfWord  \\\n",
       "0              0.194444                 72            14   \n",
       "1              0.272727                 66            18   \n",
       "2              0.246154                 65            16   \n",
       "3              0.250000                 84            21   \n",
       "4              0.207547                 53            11   \n",
       "...                 ...                ...           ...   \n",
       "20032          0.273585                106            29   \n",
       "20034          0.145161                 62             9   \n",
       "20036          0.227273                 44            10   \n",
       "20042          0.164384                 73            12   \n",
       "20045          0.309524                 42            13   \n",
       "\n",
       "       RatioArticlesAndWords  RatioAuxiliaryVerbsAndWords  \\\n",
       "0                   0.071429                     0.000000   \n",
       "1                   0.055556                     0.111111   \n",
       "2                   0.062500                     0.000000   \n",
       "3                   0.142857                     0.047619   \n",
       "4                   0.090909                     0.000000   \n",
       "...                      ...                          ...   \n",
       "20032               0.034483                     0.103448   \n",
       "20034               0.111111                     0.000000   \n",
       "20036               0.100000                     0.000000   \n",
       "20042               0.083333                     0.000000   \n",
       "20045               0.000000                     0.000000   \n",
       "\n",
       "       RatioConjunctionsAndWords  RatioInterjectionsAndWords  \\\n",
       "0                       0.071429                    0.000000   \n",
       "1                       0.055556                    0.000000   \n",
       "2                       0.062500                    0.000000   \n",
       "3                       0.000000                    0.047619   \n",
       "4                       0.000000                    0.000000   \n",
       "...                          ...                         ...   \n",
       "20032                   0.103448                    0.000000   \n",
       "20034                   0.000000                    0.000000   \n",
       "20036                   0.000000                    0.000000   \n",
       "20042                   0.000000                    0.000000   \n",
       "20045                   0.076923                    0.000000   \n",
       "\n",
       "       RatioPrepositionsAndWords  RatioPronounsAndWords  \\\n",
       "0                       0.285714               0.000000   \n",
       "1                       0.111111               0.222222   \n",
       "2                       0.062500               0.250000   \n",
       "3                       0.095238               0.047619   \n",
       "4                       0.272727               0.000000   \n",
       "...                          ...                    ...   \n",
       "20032                   0.068966               0.137931   \n",
       "20034                   0.000000               0.000000   \n",
       "20036                   0.100000               0.000000   \n",
       "20042                   0.083333               0.000000   \n",
       "20045                   0.000000               0.230769   \n",
       "\n",
       "       RatioSpacesAndCharacters  TotalArticles  TotalAuxiliaryVerbs  \\\n",
       "0                      0.180556              1                    0   \n",
       "1                      0.257576              1                    2   \n",
       "2                      0.230769              1                    0   \n",
       "3                      0.238095              3                    1   \n",
       "4                      0.188679              1                    0   \n",
       "...                         ...            ...                  ...   \n",
       "20032                  0.264151              1                    3   \n",
       "20034                  0.129032              1                    0   \n",
       "20036                  0.204545              1                    0   \n",
       "20042                  0.150685              1                    0   \n",
       "20045                  0.285714              0                    0   \n",
       "\n",
       "       TotalConjunctions  TotalConsonants  TotalInterjections  \\\n",
       "0                      1               28                   0   \n",
       "1                      1               23                   0   \n",
       "2                      1               25                   0   \n",
       "3                      0               33                   1   \n",
       "4                      0               14                   0   \n",
       "...                  ...              ...                 ...   \n",
       "20032                  3               40                   0   \n",
       "20034                  0               24                   0   \n",
       "20036                  0               15                   0   \n",
       "20042                  0               24                   0   \n",
       "20045                  1               20                   0   \n",
       "\n",
       "       TotalPrepositions  TotalPronouns  TotalSpaces  TotalVowels  gender  \n",
       "0                      4              0           13           28    male  \n",
       "1                      2              4           17           23    male  \n",
       "2                      1              4           15           25    male  \n",
       "3                      2              1           20           33    male  \n",
       "4                      3              0           10           14  female  \n",
       "...                  ...            ...          ...          ...     ...  \n",
       "20032                  2              4           28           40    male  \n",
       "20034                  0              0            8           24   brand  \n",
       "20036                  1              0            9           15  female  \n",
       "20042                  1              0           11           24   brand  \n",
       "20045                  0              3           12           20  female  \n",
       "\n",
       "[18412 rows x 20 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Storing the 'duplicate' dataframe that we created where in there are 19 features extracted already to the main variable of the data which is 'data_text_label'</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text_label = duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analyzing the classes on the dependent variable</b>\n",
    "\n",
    "In this code, we are getting the number of records or occurences in the 'gender' per class. As of now, there are 5 classes in the dependent variable which are female, male, brand or typically a type of product or business manufactured by a particular company under a particular name, unknown or users that are not identified, and XXX refers to the null or missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female     6573\n",
       "male       6136\n",
       "brand      4729\n",
       "unknown     877\n",
       "XXX          97\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text_label['gender'].value_counts()\n",
    "#data_text_label['gender'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Removal of insignificant classes in 'gender' and checking if there are still missing values</b>\n",
    "\n",
    "We remove the brand, unknown, and the missing or null values since we are only focused on the gender of the user which are male and female. Since gender carries rich and significant information concerning the male and female social activities. Then, we are checking if there are still any missing or null values and the output is 'False' meaning there are no missing values anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text_label = data_text_label[data_text_label['gender'] != 'brand']\n",
    "data_text_label = data_text_label[data_text_label['gender'] != 'unknown']\n",
    "data_text_label = data_text_label[data_text_label['gender'] != 'XXX']\n",
    "data_text_label['gender'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Checking the shape of the dataset</b>\n",
    "\n",
    "After doing lots of data pre-processing techniques, we are just checking the shape of the dataset. Since we remove the 3 insignificant classes from 'gender' which are brand, unknown, and missing or null values. We remove the stopwords, duplicate records, and other insignificant values and noise in our data. The shape of our dataset is now (12709, 20) since there are 12709 records and 20 columns which are the gender and the 19 extracted features because we are dealing with a text-based gender classifcation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12709, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text_label['gender'].value_counts()\n",
    "data_text_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Converting values of 'gender' from string to int</b>\n",
    "\n",
    "In order to implement the machine learning models which are Naive Bayes and SVM from the dataset. The values of the data should be integer so that the model can process it. Since computer and machines cannot process strings but integers only. So we will convert 'Male' to 1 and 'Female' to 0 then store it in 'gender'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gender(v):\n",
    "  if v == 'male':\n",
    "    return 1\n",
    "  elif v == 'female':\n",
    "    return 0\n",
    "\n",
    "data_text_label['gender'] = data_text_label.apply(lambda x: convert_gender(x['gender']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the gender column has now integer values instead of string. 0 which represents 'Female' and 1 which represents 'Male'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveNumOfCharWord</th>\n",
       "      <th>LengthOfCharacter</th>\n",
       "      <th>LengthOfWord</th>\n",
       "      <th>RatioArticlesAndWords</th>\n",
       "      <th>RatioAuxiliaryVerbsAndWords</th>\n",
       "      <th>RatioConjunctionsAndWords</th>\n",
       "      <th>RatioInterjectionsAndWords</th>\n",
       "      <th>RatioPrepositionsAndWords</th>\n",
       "      <th>RatioPronounsAndWords</th>\n",
       "      <th>RatioSpacesAndCharacters</th>\n",
       "      <th>TotalArticles</th>\n",
       "      <th>TotalAuxiliaryVerbs</th>\n",
       "      <th>TotalConjunctions</th>\n",
       "      <th>TotalConsonants</th>\n",
       "      <th>TotalInterjections</th>\n",
       "      <th>TotalPrepositions</th>\n",
       "      <th>TotalPronouns</th>\n",
       "      <th>TotalSpaces</th>\n",
       "      <th>TotalVowels</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>66</td>\n",
       "      <td>18</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.246154</td>\n",
       "      <td>65</td>\n",
       "      <td>16</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>84</td>\n",
       "      <td>21</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207547</td>\n",
       "      <td>53</td>\n",
       "      <td>11</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AveNumOfCharWord  LengthOfCharacter  LengthOfWord  RatioArticlesAndWords  \\\n",
       "0          0.194444                 72            14               0.071429   \n",
       "1          0.272727                 66            18               0.055556   \n",
       "2          0.246154                 65            16               0.062500   \n",
       "3          0.250000                 84            21               0.142857   \n",
       "4          0.207547                 53            11               0.090909   \n",
       "\n",
       "   RatioAuxiliaryVerbsAndWords  RatioConjunctionsAndWords  \\\n",
       "0                     0.000000                   0.071429   \n",
       "1                     0.111111                   0.055556   \n",
       "2                     0.000000                   0.062500   \n",
       "3                     0.047619                   0.000000   \n",
       "4                     0.000000                   0.000000   \n",
       "\n",
       "   RatioInterjectionsAndWords  RatioPrepositionsAndWords  \\\n",
       "0                    0.000000                   0.285714   \n",
       "1                    0.000000                   0.111111   \n",
       "2                    0.000000                   0.062500   \n",
       "3                    0.047619                   0.095238   \n",
       "4                    0.000000                   0.272727   \n",
       "\n",
       "   RatioPronounsAndWords  RatioSpacesAndCharacters  TotalArticles  \\\n",
       "0               0.000000                  0.180556              1   \n",
       "1               0.222222                  0.257576              1   \n",
       "2               0.250000                  0.230769              1   \n",
       "3               0.047619                  0.238095              3   \n",
       "4               0.000000                  0.188679              1   \n",
       "\n",
       "   TotalAuxiliaryVerbs  TotalConjunctions  TotalConsonants  \\\n",
       "0                    0                  1               28   \n",
       "1                    2                  1               23   \n",
       "2                    0                  1               25   \n",
       "3                    1                  0               33   \n",
       "4                    0                  0               14   \n",
       "\n",
       "   TotalInterjections  TotalPrepositions  TotalPronouns  TotalSpaces  \\\n",
       "0                   0                  4              0           13   \n",
       "1                   0                  2              4           17   \n",
       "2                   0                  1              4           15   \n",
       "3                   1                  2              1           20   \n",
       "4                   0                  3              0           10   \n",
       "\n",
       "   TotalVowels  gender  \n",
       "0           28       1  \n",
       "1           23       1  \n",
       "2           25       1  \n",
       "3           33       1  \n",
       "4           14       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text_label.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implementation of Gender Classification using SVM and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this gender classification task, we will be implementing two machine learning algorithms which are:\n",
    "1. <b>SVM (Support Vector Machine)</b> - is a supervised machine learning algorithm used for classification and regression problems. However, SVM is used most likely in classification problems. SVM works by plotting each data item as a point in n-dimensional space (where n is the number of features or independent variables that the dataset has) with the value of a particular coordinate which is the value of each feature. Then, perform classification by finding the hyper-plane that differentiates the two classes very well.\n",
    "2. <b>Naive Bayes</b> - is a powerful probabilistic machine learning algorithm that is used for classification. Naive Bayes works by using the Bayes’ Theorem which is predicting the probabilities for each class such as the probability of that given record or data point belongs to a particular class. The class or category with the highest probability is considered as the most likely class. This study will specifically implement Multinomial Naive Bayes, the only difference of it with Naive Bayes is that it is a multinomial distribution which requires integer feature counts, rather than some other distribution. This works well and is suitable for classification with discrete features, such as word counts in text which is one of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Splitting the dataset into training data and testing data</b>\n",
    "\n",
    "First step is of course we need to split the dataset into training data and testing data. In this case we set the test size as 25% making the training size 75% and adjusted the 'random_state' to 69 since it is the optimal value. \n",
    "1. <b>Training data</b> - is used to fit the machine learning model.\n",
    "2. <b>Testing data</b> - is used to evaluate the fit machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9531, 19)\n",
      "(3178, 19)\n",
      "(9531,)\n",
      "(3178,)\n",
      "Testing Data\n",
      "Male  Count:  1525\n",
      "Female Count:  1653\n",
      "Training Data\n",
      "Male  Count:  4611\n",
      "Female Count:  4920\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_text_label[[\"AveNumOfCharWord\", \"LengthOfCharacter\", \"LengthOfWord\", \"RatioArticlesAndWords\", \"RatioAuxiliaryVerbsAndWords\", \"RatioConjunctionsAndWords\", \"RatioInterjectionsAndWords\", \"RatioPrepositionsAndWords\", \"RatioPronounsAndWords\", \"RatioSpacesAndCharacters\", \"TotalArticles\", \"TotalAuxiliaryVerbs\", \"TotalConjunctions\", \"TotalConsonants\", \"TotalInterjections\", \"TotalPrepositions\", \"TotalPronouns\", \"TotalSpaces\", \"TotalVowels\"]]\n",
    "y = data_text_label[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=69)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "male_count = 0\n",
    "female_count = 0\n",
    "\n",
    "for i in y_test:\n",
    "    if(i==1):\n",
    "        male_count+=1\n",
    "    else:\n",
    "        female_count+=1\n",
    "\n",
    "        \n",
    "        \n",
    "print(\"Testing Data\")\n",
    "print(\"Male  Count: \", male_count)\n",
    "print(\"Female Count: \", female_count)\n",
    "\n",
    "male_count = 0\n",
    "female_count = 0\n",
    "\n",
    "for i in y_train:\n",
    "    if(i==1):\n",
    "        male_count+=1\n",
    "    else:\n",
    "        female_count+=1\n",
    "\n",
    "        \n",
    "        \n",
    "print(\"Training Data\")\n",
    "print(\"Male  Count: \", male_count)\n",
    "print(\"Female Count: \", female_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-12257f58aee1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_notebook_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnected\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import plotly.tools as tls\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "y = data_text_label[\"gender\"]\n",
    "data = [go.Bar(\n",
    "            x = train.gender.map(y).unique(),\n",
    "            y = train.gender.value_counts().values,\n",
    "            marker= dict(colorscale='Jet',\n",
    "                         color = train.author.value_counts().values\n",
    "                        ),\n",
    "            text='Text entries attributed to Author'\n",
    "    )]\n",
    "\n",
    " \n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Target variable distribution'\n",
    ")\n",
    "\n",
    " \n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    " \n",
    "\n",
    "py.iplot(fig, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Dataset Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the dataset into training data and testing data, we will now proceed in training the training data and fit it in the Support Vector Machine (SVM) model specifically in the Support Vector Classification (SVC). The parameters used in SVM are the following:\n",
    "1. <b>C</b> - is the regularization parameter. The strength of the regularization is inversely proportional to C. The value of C is set to its default value which is 1.0 since it is the optimal value in this case. \n",
    "2. <b>kernel</b> - is the kernel type to be used in the algorithm. The kernel that we used is 'linear' since the data can be linearly separable.\n",
    "\n",
    "After fitting the training data into the SVM model, we will now proceed to prediction of outcomes using the testing data. Then, we will get the obtained accuracy score from the SVM model that we created which is 56%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  55.947136563876654\n",
      "Accuracy: 0.559471\n",
      "Precision: 0.559581\n",
      "Recall: 0.384918\n",
      "F1 score: 0.456099\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "SVM = svm.SVC(C=1.0, kernel='linear')\n",
    "SVM.fit(X_train, y_train)\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, y_test)*100)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, predictions_SVM)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, predictions_SVM)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, predictions_SVM)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, predictions_SVM)\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1191</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>938</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  1191  462\n",
       "1   938  587"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = np.unique(y_test)\n",
    "cmtx =  confusion_matrix(y_test, predictions_SVM, labels=labels)\n",
    "\n",
    "pd.DataFrame(cmtx, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing the gender classification task using Support Vector Machine (SVM), we will now implement it using Naive Bayes specifically Multinomial Naive Bayes since it works well on discrete features, such as word counts in text. The parameter used in Multinomial Naive Bayes is:\n",
    "1. <b>alpha</b> - is the smoothing parameter (0 for no smoothing). In this case, we used the default value of '1.0' since it is the optimal value. \n",
    "\n",
    "We will now create the Multinomial Naive Bayes model by training the training data and fit it in the Multinomial Naive Bayes model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB(alpha=1.0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the training data into the Multinomial Naive Bayes model, we will now proceed to prediction of outcomes using the testing data. Then, we will get the obtained accuracy score from the Multinomial Naive Bayes model that we created which is 56%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  0.5635619886721208\n",
      "Accuracy: 0.563562\n",
      "Precision: 0.547196\n",
      "Recall: 0.524590\n",
      "F1 score: 0.535655\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Accuracy Score -> \", np.mean(predicted == y_test))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, predicted)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, predicted)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, predicted)\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>991</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  991  662\n",
       "1  725  800"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = np.unique(y_test)\n",
    "cmtx =  confusion_matrix(y_test, predicted, labels=labels)\n",
    "\n",
    "pd.DataFrame(cmtx, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_units = ['SVM', 'Naive Bayes']\n",
    "\n",
    "y_units = [f1_score(predictions_SVM, y_test)*100, f1_score(predicted, y_test)*100]\n",
    "\n",
    "model_label = ['SVM', 'Naive Bayes']\n",
    "\n",
    "plt.bar(x_units, y_units, tick_label=model_label,\n",
    "        width=0.8, color=['red', 'blue'])\n",
    "\n",
    "plt.xlabel('Machine Learning Algorithm')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('SVM Vs. Naive Bayes')\n",
    "\n",
    " \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning (C, Alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  56.19886721208307\n",
      "Accuracy: 0.561989\n",
      "Precision: 0.563394\n",
      "Recall: 0.387541\n",
      "F1 score: 0.459207\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "SVM = svm.SVC(C=10.0, kernel='linear')\n",
    "SVM.fit(X_train, y_train)\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, y_test)*100)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, predictions_SVM)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, predictions_SVM)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, predictions_SVM)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, predictions_SVM)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  0.5641913152926369\n",
      "Accuracy: 0.564191\n",
      "Precision: 0.547814\n",
      "Recall: 0.525902\n",
      "F1 score: 0.536634\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB(alpha=10.0).fit(X_train, y_train)\n",
    "import numpy as np\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Accuracy Score -> \", np.mean(predicted == y_test))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, predicted)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, predicted)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, predicted)\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Application of Pre-Processing Techniques "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More pre-processing techniques are applied for experimentation to analyze which will increase the accuracy and performance of each model since many machine learning algorithms perform better when features are on a similar scale and near to normally distributed. The pre-processing techniques performed in the two machine learning models which are Multinomial Naive Bayes and Support Vector Machine (SVM) are:\n",
    "1. <b>StandardScaler</b> - standardize features by removing the mean and scaling to unit variance\n",
    "2. <b>MinMaxScaler</b> - transform features by scaling each feature to a given range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_text_label[[\"AveNumOfCharWord\", \"LengthOfCharacter\", \"LengthOfWord\", \"RatioArticlesAndWords\", \"RatioAuxiliaryVerbsAndWords\", \"RatioConjunctionsAndWords\", \"RatioInterjectionsAndWords\", \"RatioPrepositionsAndWords\", \"RatioPronounsAndWords\", \"RatioSpacesAndCharacters\", \"TotalArticles\", \"TotalAuxiliaryVerbs\", \"TotalConjunctions\", \"TotalConsonants\", \"TotalInterjections\", \"TotalPrepositions\", \"TotalPronouns\", \"TotalSpaces\", \"TotalVowels\"]]\n",
    "y = data_text_label[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=69)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "scaler.fit(X_train) \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_train.shape)\n",
    "#print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  56.01006922592826\n",
      "Accuracy: 0.560101\n",
      "Precision: 0.562809\n",
      "Recall: 0.373115\n",
      "F1 score: 0.448738\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma=\"auto\", class_weight = None)\n",
    "SVM.fit(X_train, y_train)\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, y_test)*100)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, predictions_SVM)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, predictions_SVM)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, predictions_SVM)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, predictions_SVM)\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1211</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>956</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  1211  442\n",
       "1   956  569"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = np.unique(y_test)\n",
    "cmtx =  confusion_matrix(y_test, predictions_SVM, labels=labels)\n",
    "\n",
    "pd.DataFrame(cmtx, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB(alpha=1.0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  54.27942101950912\n",
      "Accuracy: 0.542794\n",
      "Precision: 0.524658\n",
      "Recall: 0.502295\n",
      "F1 score: 0.513233\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "print(\"Naive Bayes Accuracy Score -> \", np.mean(predicted == y_test)*100)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, predicted)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, predicted)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, predicted)\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>959</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>759</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  959  694\n",
       "1  759  766"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = np.unique(y_test)\n",
    "cmtx =  confusion_matrix(y_test, predicted, labels=labels)\n",
    "\n",
    "pd.DataFrame(cmtx, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_units = ['SVM', 'Naive Bayes']\n",
    "\n",
    "y_units = [f1_score(predictions_SVM, y_test)*100, f1_score(predicted, y_test)*100]\n",
    "\n",
    "model_label = ['SVM', 'Naive Bayes']\n",
    "\n",
    "plt.bar(x_units, y_units, tick_label=model_label,\n",
    "        width=0.8, color=['red', 'blue'])\n",
    "\n",
    "plt.xlabel('Machine Learning Algorithm')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('SVM Vs. Naive Bayes')\n",
    "\n",
    " \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  56.01006922592826\n",
      "Accuracy: 0.560101\n",
      "Precision: 0.561234\n",
      "Recall: 0.381639\n",
      "F1 score: 0.454333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_text_label[[\"AveNumOfCharWord\", \"LengthOfCharacter\", \"LengthOfWord\", \"RatioArticlesAndWords\", \"RatioAuxiliaryVerbsAndWords\", \"RatioConjunctionsAndWords\", \"RatioInterjectionsAndWords\", \"RatioPrepositionsAndWords\", \"RatioPronounsAndWords\", \"RatioSpacesAndCharacters\", \"TotalArticles\", \"TotalAuxiliaryVerbs\", \"TotalConjunctions\", \"TotalConsonants\", \"TotalInterjections\", \"TotalPrepositions\", \"TotalPronouns\", \"TotalSpaces\", \"TotalVowels\"]]\n",
    "y = data_text_label[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=69)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_train.shape)\n",
    "#print(y_test.shape)\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma=\"auto\", class_weight = None)\n",
    "SVM.fit(X_train, y_train)\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, y_test)*100)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, predictions_SVM)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, predictions_SVM)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, predictions_SVM)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, predictions_SVM)\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1198</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>943</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  1198  455\n",
       "1   943  582"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = np.unique(y_test)\n",
    "cmtx =  confusion_matrix(y_test, predictions_SVM, labels=labels)\n",
    "\n",
    "pd.DataFrame(cmtx, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  54.027690371302704\n",
      "Accuracy: 0.540277\n",
      "Precision: 0.550794\n",
      "Recall: 0.227541\n",
      "F1 score: 0.322042\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data_text_label[[\"AveNumOfCharWord\", \"LengthOfCharacter\", \"LengthOfWord\", \"RatioArticlesAndWords\", \"RatioAuxiliaryVerbsAndWords\", \"RatioConjunctionsAndWords\", \"RatioInterjectionsAndWords\", \"RatioPrepositionsAndWords\", \"RatioPronounsAndWords\", \"RatioSpacesAndCharacters\", \"TotalArticles\", \"TotalAuxiliaryVerbs\", \"TotalConjunctions\", \"TotalConsonants\", \"TotalInterjections\", \"TotalPrepositions\", \"TotalPronouns\", \"TotalSpaces\", \"TotalVowels\"]]\n",
    "y = data_text_label[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=69)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_train.shape)\n",
    "#print(y_test.shape)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB(alpha=1.0).fit(X_train, y_train)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Accuracy Score -> \", np.mean(predicted == y_test)*100)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, predicted)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, predicted)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, predicted)\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1370</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1178</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  1370  283\n",
       "1  1178  347"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = np.unique(y_test)\n",
    "cmtx =  confusion_matrix(y_test, predicted, labels=labels)\n",
    "\n",
    "pd.DataFrame(cmtx, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_units = ['SVM', 'Naive Bayes']\n",
    "\n",
    "y_units = [f1_score(predictions_SVM, y_test)*100, f1_score(predicted, y_test)*100]\n",
    "\n",
    "model_label = ['SVM', 'Naive Bayes']\n",
    "\n",
    "plt.bar(x_units, y_units, tick_label=model_label,\n",
    "        width=0.8, color=['red', 'blue'])\n",
    "\n",
    "plt.xlabel('Machine Learning Algorithm')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('SVM Vs. Naive Bayes')\n",
    "\n",
    " \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizer with Standard Scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  55.160478288231594\n",
      "Accuracy: 0.551605\n",
      "Precision: 0.531566\n",
      "Recall: 0.552131\n",
      "F1 score: 0.541653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_text_label[[\"AveNumOfCharWord\", \"LengthOfCharacter\", \"LengthOfWord\", \"RatioArticlesAndWords\", \"RatioAuxiliaryVerbsAndWords\", \"RatioConjunctionsAndWords\", \"RatioInterjectionsAndWords\", \"RatioPrepositionsAndWords\", \"RatioPronounsAndWords\", \"RatioSpacesAndCharacters\", \"TotalArticles\", \"TotalAuxiliaryVerbs\", \"TotalConjunctions\", \"TotalConsonants\", \"TotalInterjections\", \"TotalPrepositions\", \"TotalPronouns\", \"TotalSpaces\", \"TotalVowels\"]]\n",
    "y = data_text_label[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=69)\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "scaler.fit(X_train) \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_train.shape)\n",
    "#print(y_test.shape)\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma=\"auto\", class_weight = None)\n",
    "SVM.fit(X_train, y_train)\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, y_test)*100)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, predictions_SVM)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, predictions_SVM)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, predictions_SVM)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, predictions_SVM)\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>911</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>683</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  911  742\n",
       "1  683  842"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = np.unique(y_test)\n",
    "cmtx =  confusion_matrix(y_test, predictions_SVM, labels=labels)\n",
    "\n",
    "pd.DataFrame(cmtx, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  55.947136563876654\n",
      "Accuracy: 0.559471\n",
      "Precision: 0.538180\n",
      "Recall: 0.577705\n",
      "F1 score: 0.557242\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB(alpha=1.0).fit(X_train, y_train)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Accuracy Score -> \", np.mean(predicted == y_test)*100)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, predicted)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, predicted)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, predicted)\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>897</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>644</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  897  756\n",
       "1  644  881"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = np.unique(y_test)\n",
    "cmtx =  confusion_matrix(y_test, predicted, labels=labels)\n",
    "\n",
    "pd.DataFrame(cmtx, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_units = ['SVM', 'Naive Bayes']\n",
    "\n",
    "y_units = [f1_score(predictions_SVM, y_test)*100, f1_score(predicted, y_test)*100]\n",
    "\n",
    "model_label = ['SVM', 'Naive Bayes']\n",
    "\n",
    "plt.bar(x_units, y_units, tick_label=model_label,\n",
    "        width=0.8, color=['red', 'blue'])\n",
    "\n",
    "plt.xlabel('Machine Learning Algorithm')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('SVM Vs. Naive Bayes')\n",
    "\n",
    " \n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
